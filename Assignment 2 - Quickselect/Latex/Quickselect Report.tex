\documentclass[
12pt,
a4paper,
oneside,
headinclude,
footinclude]{article}



\usepackage[table,xcdraw,svgnames]{xcolor}
\usepackage[capposition=bottom]{floatrow}
\usepackage[colorlinks]{hyperref} % to add hyperlinks
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{csquotes}
\usepackage{amsmath} % For the big bracket
\usepackage[export]{adjustbox}[2011/08/13]
% \usepackage{subfig}
\usepackage{array}
\usepackage{url}
\usepackage{graphicx} % to insert images
\usepackage{titlepic} % to insert image on front page
\usepackage{geometry} % to define margin
\usepackage{listings} % to add code
\usepackage{caption}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[utf8]{inputenc} % Required for including letters with accents
\usepackage{color}
\usepackage{subcaption}
\usepackage[nochapters, eulermath, dottedtoc ]{classicthesis}
\usepackage{listings} % For R code

\usepackage{minted} % For Rust code

\usepackage{color}

\usemintedstyle{tango}

\usepackage{etoolbox}


\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\lstset{frame=tb,
  language=R,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3,
  frame=none
}

\definecolor{webbrown}{rgb}{.6,0,0}

\usepackage{titlesec} % to customize titles
\titleformat{\chapter}{\normalfont\huge}{\textbf{\thechapter.}}{20pt}{\huge\textbf}[\vspace{2ex}\titlerule] % to customize chapter title aspect
\titleformat{\section} % to customize section titles
  {\fontsize{14}{15}\bfseries}{\thesection}{1em}{}

\titlespacing*{\chapter}{0pt}{-50pt}{20pt} % to customize chapter title space

\graphicspath{ {../Figures/} } % images folder
\parindent0pt \parskip10pt % make block paragraphs
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm,headheight=3cm,headsep=3cm,footskip=1cm} % define margin
\hyphenation{Fortran hy-phen-ation}

\AtBeginDocument{%
    \hypersetup{
    colorlinks=true, breaklinks=true, bookmarks=true,
    urlcolor=webbrown, citecolor=Black, linkcolor=Black% Link colors
}}

\pagestyle{plain}
\title{\textbf{Quickselect - Analysis of the expected number of comparisons}}
\author{{Alberto Parravicini}}
\date{}	% default \today

% =============================================== BEGIN

\begin{document}
\maketitle
\pagenumbering{roman}
\setcounter{page}{1}

\section{Abstract}
The following report will analyze the number of comparisons performed by a \textbf{Rust} implementation of the \textbf{Quickselect} algorithm, a randomized algorithm used to find the $k-th$ smallest element in an unordered list.

The first section of the report presents the algorithm, and its \textbf{Rust implementation}.

The second section studies the number of \textbf{comparisons} between done by the algorithm,
i.e. how many elements from the input list must be compared to each other to give the desired output.
This numbers are then compared to the theoretical expected number of comparisons done by the algorithm.\newline
The algorithm is tested against vectors with increasing size $n$ and various ranges of $k$.

As addendum, an analysis of the \textbf{execution time} of \textit{Quickselect} is reported, to show how the number of comparisons influences the running time of the algorithm.

\section{Quickselect's algorithm implementation}
\vspace{-5mm}
\subsection{Theoretical background}
\vspace{-5mm}
Given a list of $\mathbf{n}$ elements for which exists a total order under $\mathbf{\leq}$, the \textbf{Quickselect} algorithm is used to find the $\mathbf{k-th}$ smallest element in the list (also referred as element of \textit{rank k}), for $\mathbf{k \in [1,\ n]}$.

\newpage
To select the element of rank $k$ (with $1 \leq k \leq n$), the algorithm works as follow:

\texttt {\textcolor{Maroon}{quickselect(list, start, end)}: \newline
	\null\quad\quad pick an element at random from the list, \newline
    \null\quad\quad\quad\quad in the range [start, end], call it \textbf{pivot}; \newline
	\null\quad\quad put all the elements $<$ pivot on its left; \newline
	\null\quad\quad put all the elements $>$ pivot on its right; \newline
    \null\quad\quad the pivot is now in its sorted position in the list: \newline
    \null\quad\quad\quad\quad if \textcolor{RoyalBlue}{position(pivot) $==$ k}, return it; \newline
    \null\quad\quad\quad\quad if \textcolor{RoyalBlue}{position(pivot) $<$ k}, return \textcolor{Maroon}{quickselect(start, position(pivot))}; \newline
    \null\quad\quad\quad\quad if \textcolor{RoyalBlue}{position(pivot) $>$ k}, return \textcolor{Maroon}{quickselect(position(pivot), end)}; \newline}

It can be seen how there is a close resemblance between the \textbf{Quickselect} and the \textbf{Quicksort} algorithms. \\
Indeed, \textbf{Quickselect} can be seen as a modified version of \textbf{Quicksort} in which the recursion is applied only to the portion of the list where the desired element of \textit{rank k} is expected to be found.

\vspace{-5mm}
\subsection{Rust implementation}
\vspace{-5mm}
\textit{Rust} was chosen as the programming language of the implementation as the inherent speed of the language, combined with the relative simplicity of the \textbf{Quickselect} algorithm, make it a good candidate for performing a large number of tests over many different parameter values.

What follows are snippets of code, to explain how the \textbf{Quickselect} algorithm was implemented.
The following code is inspired to the pseudo-code of the algorithm found in \textit{Wikipedia}. \cite{quickselect_wiki}

$\bullet$ \textbf{Quickselect}
\begin{minted}[baselinestretch=1, fontsize=\footnotesize]{rust}
fn quickselect(vec: &mut Vec<usize>,
               start: usize, end: usize,
               k: usize, num_of_comparisons: u32) -> (usize, u32) {
    let mut num_of_comparisons: u32 = num_of_comparisons;

    if k < start || k > end {
        panic!("INVALID VALUE OF K: {}", k)
    }
    // If just one element is present, return it;
    if start >= end {
        return (vec[end], num_of_comparisons)
    }
    let pivot_index = rand::thread_rng().gen_range(start, end + 1);
    // Put the current pivot in its correct place, and return its position;
    let (pivot_index, temp_num_of_comparisons) = partition(vec, start, end, pivot_index);
    num_of_comparisons += temp_num_of_comparisons;

    // Apply the sorting only where the desired element could be,
    // or return it if it was found;
    if k == pivot_index {
        return (vec[k], num_of_comparisons)
    }
    else if k < pivot_index {
        let result = quickselect(vec, start, pivot_index, k, num_of_comparisons);
        return result
    }
    else {
        let result = quickselect(vec, pivot_index + 1, end, k, num_of_comparisons);
        return result
    }
}
\end{minted}

$\bullet$ \textbf{Select a pivot and put it into its sorted position}
\begin{minted}[baselinestretch=1, fontsize=\footnotesize]{rust}
fn partition(vec: &mut Vec<usize>,
             start: usize, end: usize,
             pivot_index: usize) -> (usize, u32) {
    let pivot_value = vec[pivot_index];
    let mut temp_num_of_comparisons: u32 = 0;

    // Temporarily put the pivot at the end of the vector;
    vec.swap(pivot_index, end);
    let mut store_index = start;
    for i in start..end {
        temp_num_of_comparisons += 1;
        if vec[i] < pivot_value {
            // If a value lower than the pivot is found, put it in the left part of the vector;
            vec.swap(store_index, i);
            // store_index keeps track of how many values lower that the pivot exist,
            // and where the pivot should be placed at the end;
            store_index += 1;
        }
    }
    // Put the pivot in its correct place;
    vec.swap(end, store_index);

    // Return the sorted position of the pivot and the number of comparisons performed;
    (store_index, temp_num_of_comparisons)
}

\end{minted}

\section{Analysis of the expected number of comparisons}
\vspace{-5mm}
\subsection{Theoretical background}
\vspace{-5mm}
For any two elements $X_i,\ X_j$ of the list, with $j > i$, \\
\[
    X_{i,j} = \begin{cases}
                    1\ if\ X_i,\ X_j\ are\ compared\ during\ the\ execution\ of\ the\ algorithm. \\
                    0\ else.
                \end{cases}
\]
The complexity of \textbf{Quickselect} is related to the total number of comparisons $X$ performed by the algorithm. The expected number of comparisons $E[X]$ is given by:
$$E[X] = E\Big[\sum_{i < j}{X_{i,j}}\Big] = \Big(2n + 2n \cdot\ln\Big(\frac{n}{n - k}\Big) + 2k \cdot\ln\Big(\frac{n - k}{k}\Big)\Big)\cdot (1 + o(1)) \quad\quad (\ast)$$
\vspace{-5mm}
A number of observations can be done on this formula:
\begin{itemize}
    \item If $k$ is chosen to be proportional to $n$, the number of comparisons becomes linear with respect to $n$.\\
    As an example, if $k = \frac{n}{2}$, \textcolor{Maroon}{$E[X] = n \cdot (2 + 2 \cdot \ln(2)) \cdot (1 + o(1))$}.
    
    \item The function is \textbf{even} with respect to the $k = \frac{n}{2}$ axis, i.e. $f(k + \frac{n}{2}) = f(k - \frac{n}{2})$, where $f$ is the function $(\ast)$.

    \item The function $(\ast)$ is not defined for $k = n$; that said, it can be seen that for $k = n$ the value of $(\ast)$ is very close to its value in $k = 1$. \\
        As such, the function will be approximated in this way in the following analyses.

    \item In the interval $k \in [1, n)$, it can be seen that $(\ast)$ has a single local maximum, in $k = \frac{n}{2}$. In fact, by putting the derivative of $(\ast)$ w.r.t. $k$ equal to $0$: $$\frac{\partial}{\partial k}\Big(2n + 2n \cdot\ln\Big(\frac{n}{n - k}\Big) + 2k \cdot\ln\Big(\frac{n - k}{k}\Big)\Big) = \ln\Big(\frac{n}{k} - 1 \Big) = 0$$
    From which one can find \textcolor{Maroon}{$k = \frac{n}{2}$}, which is a maximum as the second derivative is negative in the interval $k \in [1, n)$.
    Moreover, the local minima of $(\ast)$ are at the extremes of the range of $k$, and the function is concave, with no other extrema in the $k\in[1, n)$.
\end{itemize}

The \textbf{Quicksort} algorithm has been tested against lists of increasing size, while keeping the value of $k$ proportional to the size of the list, and against different values of $k$, while keeping the list size fixed.
Note that as the selection of the pivot is random, the permutation of the input list doesn't influence the number of comparisons performed by the algorithm; as such, it is possible to use already sorted list as input of the algorithm.

\subsection{\textbf{First test:} increasing size of the list, select the median}
\vspace{-5mm}
The first test consisted in running \textbf{Quickselect} on lists with \textit{increasing size $n$ and $k = \frac{n}{2}$}.
Using a value of $k$ proportional to $n$ is required to make the expected number of comparisons a function of only $n$.\\
It can be seen from $(\ast)$ that if $k = \frac{n}{2}$ (i.e. one wants to find the \textbf{median} of a list), the expected number of comparisons will be equal to $$E[X] = n \cdot (2 + 2 \cdot \ln(2)) \cdot (1 + o(1)) \quad\quad(\ast\ast)$$ linear with respect to $n$, with a constant slope of $~3.38$ (note from the following plot that $o(1)$ doesn't seem to have any meaningful impact on the number of comparisons).

In the test, the size of the lists ranged from $10000$ to $1000000$, with increments of $10000$. For each list size, \textit{Quickselect} was run $1000$ times.

The empirical number of comparisons with respect to each list size has been compared to the theoretical number of comparisons given by $(\ast\ast)$.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth, center, keepaspectratio=1]{{"increasing_size"}.pdf}
    \caption{\emph{In {\color{RoyalBlue} blue}, the measured number of comparisons. In {\color{red}red}, the theoretical number of comparisons.}}
\end{figure}

It can be seen that the empirical number of comparisons is perfectly in line with the theoretical numbers given by $(\ast\ast)$.
In fact, the \textit{mean absolute percentage error (MAPE)} \cite{mape} is of just $0.6\%$. The \textit{MAPE} is defined as $\frac{100}{m}\sum_{i = 1}^{m}{\big|1 - \frac{F_i}{A_i}\big|}$, with $A$ the theoretical number of comparisons, $F$ the observed number of comparisons, and $m$ the size of $A$ and $F$,

\subsection{\textbf{Second test:} increasing value of k, fixed list size}
As a second test, the size of the list was kept constant, and it was measured how changing the value of $k$ can influence the expected number of comparisons. By fixing $n$, the number of comparisons becomes thus a function of only $k$, ranging from $1$ to $n$.
Note that $(\ast)$ isn't defined for $k = n$, but its value can be approximated by using $k = 1$.

The test was performed on a list of size $100000$, with $k$ ranging from $1$ to $100000$, with increments of $123$ (this value is used so that it is possible to cover the entire range of $k$, as $123$ is a divisor of $100000 - 1 = 99999$). For each value of $k$, the \textit{Quickselect} algorithm was run $1000$ times.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth, center, keepaspectratio=1]{{"increasing_rank"}.pdf}
    \caption{\emph{In {\color{RoyalBlue} blue}, the measured number of comparisons. In {\color{red}red}, the theoretical number of comparisons.}}
\end{figure}

The number of comparisons seems to have a parabolic concave shape, with a maximum close to $k = \frac{n}{2}$, and measured values that are consistent with the previous theoretical results. In this case, the \textit{MAPE} is $0.79\%$.

\section{Addendum}

\subsection{Execution time analysis}
While executing the previous tests, it was possible to gather the execution times of the algorithm.\\
It is interesting to measure how the number of comparisons is related to the effective execution time.

For both the previous tests, execution times were recorded and summarized in the following plots.

The tests were performed on a \textit{Surface Pro 4} with a Intel Core i5-6300U  CPU clocked at 2.95 Ghz, and 4 GB of DDR3 RAM at 1867Mhz.

In the case of increasing list size $n$, with $k = \frac{n}{2}$, it emerges once again a linear scaling with respect to $n$.
A linear regression was performed on the measured data: the \textit{slope} of the line has been found to be $4.39 \cdot 10^{-6}$ (note that the execution times are expressed in \textit{milliseconds}), and the \textit{intercept} is $-29.02$.

If $n$ is kept constant and $k$ ranges from $1$ to $n$, it emerges a parabolic shape, which is coherent with the results found in the second test.
The maximum execution time, not considering the obvious outliers, is found for $k = \frac{n}{2}$. \\
From the measured data, it was performed a order-2 polynomial regression. The parabola found by the regression has parameters $[-1164.60, -46.11 , 364.06]$, and the measured \textit{MAPE} is $4.39\%$.

\vspace{-10mm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth, center, keepaspectratio=1]{{"increasing_size_time"}.pdf}
    \caption{\emph{In {\color{RoyalBlue} blue}, the measured execution time. In {\color{red}red}, the linear regression of the execution time.}}
\end{figure}
\vspace{-5mm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth, center, keepaspectratio=1]{{"increasing_rank_time"}.pdf}
    \caption{\emph{In {\color{RoyalBlue} blue}, the measured execution time. In {\color{red}red}, the order 2 polynomial regression of the execution time.}}
\end{figure}

\vspace{20mm}
$\bullet$ \textbf{Full code (Rust implementations + R analysis) available at \newline \href{https://github.com/AlbertoParravicini/data_structures_and_algorithms}{https://github.com/AlbertoParravicini/data\_structures\_and\_algorithms}}

\bibliographystyle{plainurl}
\bibliography{bibliography}

\end{document}

