15, 18,
20, 22,
17, 28,
13, 26,
21, 28,
24, 27,
25, 30,
19, 31), ncol = 2, byrow = T)
X_frame = data.frame(X1 = X[, 1], X2 = X[, 2])
p <- ggplot() + xlim(c(0,32)) + ylim(c(8,32))
p <- p + geom_point(size = 2, color ="#427af4", data = X_frame[1:5, ], aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#427af4", data = X_frame[1:5, ], aes(x = X1, y = X2), fill = "#427af4", alpha = 0.2)
p <- p + geom_point(size = 2, color ="#427af4", data = X_frame[6:10, ], aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#427af4", data = X_frame[6:10, ], aes(x = X1, y = X2), fill = "#427af4", alpha = 0.2)
p <- p + geom_point(size = 2, color ="#427af4", data = X_frame[11:15, ], aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#427af4", data = X_frame[11:15, ], aes(x = X1, y = X2), fill = "#427af4", alpha = 0.2)
p <- p + geom_point(size = 2, color ="#427af4", data = X_frame[16:19, ], aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#427af4", data = X_frame[16:19, ], aes(x = X1, y = X2), fill = "#427af4", alpha = 0.2)
p <- p + geom_point(size = 2, color ="#244f96", data = X_frame[1:2, ], aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#244f96", data = X_frame[1:2, ], aes(x = X1, y = X2))
p <- p + geom_point(size = 2, color ="#f49e42", data = X_frame[c(17, 12), ], aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#f49e42", data = X_frame[c(2, 12), ], aes(x = X1, y = X2), linetype="dotted")
p <- p + geom_line(size = 1, color ="#f49e42", data = X_frame[c(2, 17), ], aes(x = X1, y = X2), linetype="dotted")
p <- p + geom_point(size = 2, color ="#a52918", data = X_frame[7, ], aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#a52918", data = X_frame[c(2,7), ], aes(x = X1, y = X2), linetype="dashed")
p <- p + geom_point(size = 2, color ="#244f96", data = X_frame[1:2, ], aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#244f96", data = X_frame[1:2, ], aes(x = X1, y = X2))
p <- p + theme_void()
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
library(ggforce)
set.seed(12)
# SUPPORT PLOTS
# Draw a convex hull
X <- floor(matrix(runif(40)*20, ncol = 2))
X_frame <- data.frame(X)[-c(3, 8),]
p <- ggplot(data = X_frame, aes(x = X1, y = X2)) + geom_point(size = 2, color ="#021f91")
hull <- data.frame(X[chull(X),])
p <- p + geom_point(size = 3, color ="#a52918", data = hull, aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#a52918", data = hull, aes(x = X1, y = X2), fill = "#ff9b8e", alpha = 0.2)
p <- p + theme_void()
p
# JARVIS MARCH
X <- matrix(c(3, 21,
6, 16,
15, 10,
24, 15,
21, 21,
21, 28,
8, 25,
14, 18
), ncol = 2, byrow = T)
X_frame = data.frame(X1 = X[, 1], X2 = X[, 2])
p <- ggplot() + xlim(c(0,32)) + ylim(c(0,32))
p <- ggplot(data = X_frame, aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#244f96", data = X_frame[1:3, ], aes(x = X1, y = X2))
for (i in 5:8) {
p <- p + geom_line(size = 1, color ="#f49e42", data = X_frame[c(3, i), ], aes(x = X1, y = X2), linetype="dotted")
}
p <- p + geom_curve(aes(xend = 13.13, x = 16.95, yend = 11.25, y = 11.07), size = 1, color = "#244f96", linetype="dashed")
p <- p + geom_line(size = 1, color ="#a52918", data = X_frame[c(3, 4), ], aes(x = X1, y = X2))
p <- p + geom_point(size = 2, color ="#021f91")
p <- p + geom_point(size = 2, color ="#f49e42", data = X_frame[5:8, ], aes(x = X1, y = X2))
p <- p + geom_point(size = 2, color ="#a52918", data = X_frame[4, ], aes(x = X1, y = X2))
p <- p + theme_void()
p
# CHAN'S STEP
X <- matrix(c(3, 21,
6, 16,
10, 20,
8, 26,
5, 25,
12, 15,
15, 10,
24, 15,
21, 23,
14, 22,
12, 21,
15, 18,
20, 22,
17, 28,
13, 26,
21, 28,
24, 27,
25, 30,
19, 31), ncol = 2, byrow = T)
X_frame = data.frame(X1 = X[, 1], X2 = X[, 2])
p <- ggplot() + xlim(c(0,32)) + ylim(c(8,32))
p <- p + geom_point(size = 2, color ="#427af4", data = X_frame[1:5, ], aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#427af4", data = X_frame[1:5, ], aes(x = X1, y = X2), fill = "#427af4", alpha = 0.2)
p <- p + geom_point(size = 2, color ="#427af4", data = X_frame[6:10, ], aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#427af4", data = X_frame[6:10, ], aes(x = X1, y = X2), fill = "#427af4", alpha = 0.2)
p <- p + geom_point(size = 2, color ="#427af4", data = X_frame[11:15, ], aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#427af4", data = X_frame[11:15, ], aes(x = X1, y = X2), fill = "#427af4", alpha = 0.2)
p <- p + geom_point(size = 2, color ="#427af4", data = X_frame[16:19, ], aes(x = X1, y = X2))
p <- p + geom_polygon(color ="#427af4", data = X_frame[16:19, ], aes(x = X1, y = X2), fill = "#427af4", alpha = 0.2)
p <- p + geom_point(size = 2, color ="#244f96", data = X_frame[1:2, ], aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#244f96", data = X_frame[1:2, ], aes(x = X1, y = X2))
p <- p + geom_point(size = 2, color ="#f49e42", data = X_frame[c(17, 12), ], aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#f49e42", data = X_frame[c(2, 12), ], aes(x = X1, y = X2), linetype="dotted")
p <- p + geom_line(size = 1, color ="#f49e42", data = X_frame[c(2, 17), ], aes(x = X1, y = X2), linetype="dotted")
p <- p + geom_point(size = 2, color ="#a52918", data = X_frame[7, ], aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#a52918", data = X_frame[c(2,7), ], aes(x = X1, y = X2), linetype="dashed")
p <- p + geom_point(size = 2, color ="#244f96", data = X_frame[1:2, ], aes(x = X1, y = X2))
p <- p + geom_line(size = 1, color ="#244f96", data = X_frame[1:2, ], aes(x = X1, y = X2))
p <- p + theme_void()
p
# ACF: FPGA vs CPU
library(dplyr)
library(RColorBrewer)
library(ggplot2)
setwd("~/Progetto_ACA/docs/3_final_report/src")
data <- read.csv("../acf_fpga_vs_cpu.txt", row.names=NULL, stringsAsFactors=FALSE)
data_all <- data
data_all$speedup_percentage <- (data_all$time_cpu.sec. /  data_all$time_fpga.sec. - 1) * 100
data <- filter(data_all, num_pts <= 1000000)
cols <- c("FPGA (Zybo)" = "#ff4d4d", "CPU" = "#4f72fc")
q <- ggplot(data, aes(x=num_pts, y = time_zynq.sec., col = "FPGA (Zybo)"))
q <- q + scale_x_continuous(breaks=data$num_pts, labels=data$num_pts, limits = c(0, 320000)) + ylim(c(0,100))
q <- q + geom_line(size = 1) + geom_point(size = 2.5, color ="#800000")
q <- q + geom_line(size = 1, aes(x=num_pts, y=time_cpu.sec., col = "CPU")) + geom_point(size = 2.5, color ="#021f91", aes(x=num_pts, y=time_cpu.sec.))
q <- q + theme_minimal() + ggtitle("ACF, execution time of FPGA (Zybo) and CPU") + xlab("Number of points") + ylab("Execution time [sec]")
q <- q + theme(axis.text=element_text(size=12), axis.title=element_text(size=14), axis.text.x = element_text(angle = 90, hjust = 1)) + theme(legend.position = "right")
q <- q + scale_colour_manual(name="Type",values=cols)
q
cols <- c("FPGA (VC707)" = "#ff4d4d", "CPU" = "#4f72fc")
q <- ggplot(data, aes(x=num_pts, y = time_fpga.sec., col = "FPGA (VC707)"))
q <- q + scale_x_continuous(breaks=data$num_pts, labels=data$num_pts)
q <- q + geom_line(size = 1) + geom_point(size = 2.5, color ="#800000")
q <- q + geom_line(size = 1, aes(x=num_pts, y=time_cpu.sec., col = "CPU")) + geom_point(size = 2.5, color ="#021f91", aes(x=num_pts, y=time_cpu.sec.))
q <- q + theme_minimal() + ggtitle("ACF, execution time of FPGA (VC707) and CPU") + xlab("Number of points") + ylab("Execution time [sec]")
q <- q + theme(axis.text=element_text(size=12), axis.title=element_text(size=14), axis.text.x = element_text(angle = 90, hjust = 1)) + theme(legend.position = "right")
q <- q + scale_colour_manual(name="Type",values=cols)
q
p <- ggplot(data, aes(x=num_pts, y = speedup_percentage)) + geom_line(size = 1, col = "#00b33c")
p <- p + geom_point(size = 2.5, color ="#006622", aes(x=num_pts, y=speedup_percentage))
p <- p + theme_minimal() + ggtitle("ACF, Speedup of FPGA (VC707) over CPU") + xlab("Number of points") + ylab("Speedup Percentage")
p <- p + scale_x_continuous(breaks=data$num_pts, labels=data$num_pts) + theme(axis.text=element_text(size=12), axis.title=element_text(size=14), axis.text.x = element_text(angle = 90, hjust = 1))
#predict speedup
attach(data)
fit <- lm(speedup_percentage ~ poly(log(num_pts), 1, raw = T))
plot(x = num_pts, y = speedup_percentage, col = "red", type = "l", xlim = c(0, 10000000), ylim = c(0, 1000))
lines(x = num_pts, y = fit$fitted.values, col = "blue")
points(x = num_pts, y = fit$fitted.values, col = "blue")
pred = seq(1100000, 10000000, by = 300000)
y = predict(fit, newdata = data.frame(num_pts = pred))
pred_speedup <- y
lines(x = pred, y = y, col = "green")
points(x = pred, y = y, col = "green")
# predict cpu
fit <- lm(time_cpu.sec. ~ poly(num_pts, 2, raw = T))
plot(x = num_pts, y = time_cpu.sec., col = "red", type = "l", xlim = c(0, 10000000), ylim = c(0, 100000))
lines(x = num_pts, y = fit$fitted.values, col = "blue")
points(x = num_pts, y = fit$fitted.values, col = "blue")
pred = seq(1100000, 10000000, by = 300000)
y = predict(fit, newdata = data.frame(num_pts = pred))
pred_cpu <- y
lines(x = pred, y = y, col = "green")
points(x = pred, y = y, col = "green")
# predict fpga
fit <- lm(time_fpga.sec. ~ poly(num_pts, 2, raw = T))
plot(x = num_pts, y = time_fpga.sec., col = "red", type = "l", xlim = c(0, 10000000), ylim = c(0, 100000))
lines(x = num_pts, y = fit$fitted.values, col = "blue")
points(x = num_pts, y = fit$fitted.values, col = "blue")
pred = seq(1100000, 10000000, by = 300000)
y = predict(fit, newdata = data.frame(num_pts = pred))
pred_fpga <- y
lines(x = pred, y = y, col = "green")
points(x = pred, y = y, col = "green")
pred_table <- data.frame(num_pts = c(data$num_pts, pred), speedup = c(data$speedup_percentage, (pred_cpu/pred_fpga - 1)*100))
#pred_table <- data.frame(num_pts = c(data$num_pts), speedup = c(data$speedup_percentage))
pred_table$predicted = ifelse(pred_table$num_pts <= 1000000, 0, 1)
p <- ggplot(pred_table, aes(num_pts, speedup, col = as.factor(predicted))) + scale_color_brewer(palette = "Dark2", name = "Predicted", labels = c("No", "Yes"))
p <- p + geom_line(size = 1) + geom_point(size = 2.5,  aes(num_pts, speedup, col = as.factor(predicted)))
p <- p + ggtitle("Speedup prediction, up to 10000000 points") + xlab("Number of points") + ylab("Speedup Percentage")
p <- p + theme_minimal()  + scale_y_continuous(breaks=c(seq(0, 800, by = 100)), labels=c(seq(0, 800, by = 100)), limits = c(100, 800))
extra_points <- data.frame(num_pts = c(data_all[18:19, ]$num_pts), speedup = c(data_all[18:19, ]$speedup_percentage))
extra_points$predicted <- 0
p <- p + geom_point(data = extra_points, size = 2.5,  aes(num_pts, speedup, col = as.factor(predicted)))
require(scales)
p + scale_x_continuous(labels = comma)
rx = convolve(x_pad, x_pad[length(x_pad):1])
rx = rx / max(rx)
rx[1:5]
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#4f72fc", "Linear Model" = "#ff4d4d")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.6, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
# INCREASING HULL SIZE
grouped_data_hulls <- results_hulls %>% group_by(hull_size)  %>% summarise_each(funs(mean(.)), -iteration_number)#%>% summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -input_size)
p <- ggplot(grouped_data_hulls, aes(x= hull_size, y = time.sec.))
# Linear regression of the hull size
cols <- c("Real Data" = "#4f72fc", "Logarithmic Model" = "#ff4d4d")
fit <- lm(time.sec. ~ log(hull_size), data = grouped_data_hulls)
pred = seq(1000, 20000, by = 1000)
y_pred = predict(fit, newdata = data.frame(hull_size = pred))
pred_table = data.frame(x = pred, y = y_pred)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_hulls, aes(group = hull_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(data = pred_table, size = 1, aes(x = x, y = y, col = "Logarithmic Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.6, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Size of the Hull") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle(bquote(atop(.("Chan's algorithm with hulls of increasing size"), atop(italic(.("Total number of points: 40000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
# INCREASING POINTS AND HULL
grouped_data_all <- results_all %>% group_by(input_size) %>% summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -time.sec.)
# INCREASING POINTS
p <- ggplot(grouped_data_all, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#4f72fc", "n log(h)" = "#ff4d4d")
fit <- lm(time.sec. ~ (input_size * log(hull_size)), data = grouped_data_all)
pred = seq(10000, 100000, by = 10000)
y_pred = predict(fit, newdata = data.frame(input_size = pred))
pred_table = data.frame(x = pred, y = y_pred)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_all, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(data = pred_table, size = 1, aes(x = x, y = y, col = "n log(h)"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.6, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#4f72fc", "Linear Model" = "#ff4d4d")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.6, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#4f72fc", "Linear Model" = "#ff4d4d")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.4, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#4f72fc", "Linear Model" = "#ff4d4d")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.4, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle("")
# <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#4f72fc", "Linear Model" = "#ff4d4d")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.4, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle("")
# <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
# INCREASING HULL SIZE
grouped_data_hulls <- results_hulls %>% group_by(hull_size)  %>% summarise_each(funs(mean(.)), -iteration_number)#%>% summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -input_size)
p <- ggplot(grouped_data_hulls, aes(x= hull_size, y = time.sec.))
# Linear regression of the hull size
cols <- c("Real Data" = "#4f72fc", "Logarithmic Model" = "#ff4d4d")
fit <- lm(time.sec. ~ log(hull_size), data = grouped_data_hulls)
pred = seq(1000, 20000, by = 1000)
y_pred = predict(fit, newdata = data.frame(hull_size = pred))
pred_table = data.frame(x = pred, y = y_pred)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_hulls, aes(group = hull_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(data = pred_table, size = 1, aes(x = x, y = y, col = "Logarithmic Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.6, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Size of the Hull") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle(bquote(atop(.("Chan's algorithm with hulls of increasing size"), atop(italic(.("Total number of points: 40000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#4f72fc", "Linear Model" = "#ff4d4d")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.4, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle("")
# <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
# INCREASING HULL SIZE
grouped_data_hulls <- results_hulls %>% group_by(hull_size)  %>% summarise_each(funs(mean(.)), -iteration_number)#%>% summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -input_size)
p <- ggplot(grouped_data_hulls, aes(x= hull_size, y = time.sec.))
# Linear regression of the hull size
cols <- c("Real Data" = "#4f72fc", "Logarithmic Model" = "#ff4d4d")
fit <- lm(time.sec. ~ log(hull_size), data = grouped_data_hulls)
pred = seq(1000, 20000, by = 1000)
y_pred = predict(fit, newdata = data.frame(hull_size = pred))
pred_table = data.frame(x = pred, y = y_pred)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_hulls, aes(group = hull_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(data = pred_table, size = 1, aes(x = x, y = y, col = "Logarithmic Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.6, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Size of the Hull") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
#p <- p + ggtitle(bquote(atop(.("Chan's algorithm with hulls of increasing size"), atop(italic(.("Total number of points: 40000")), ""))))
p <- p + ggtitle("")
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#009688", "Linear Model" = "#E65100")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.4, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle("")
# <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#009688", "Linear Model" = "#E65100")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.4, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#009688")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle("")
# <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
library(igraph)
library(dplyr)
library(ggplot2)
library(microbenchmark)
library(scales)
set.seed()
setwd("C:/Users/albyr/Documents/data_structures_and_algorithms/Project/")
results_points <- read.csv("Results/increasing_n_2016_11_24_12_26_38.csv", header = T, sep = ",")
results_hulls <- read.csv("Results/increasing_hull_2016_11_24_14_56_23.csv", header = T, sep = ",") %>% filter(time.sec. <= 15)
results_all <- read.csv("Results/increasing_points_hull_2016_12_04_22_52_13.csv", header = T, sep = ",")
grouped_data_points <- results_points %>% group_by(input_size) %>% summarise_each(funs(median(.)), -iteration_number)#summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -hull_size)
# INCREASING POINTS
p <- ggplot(grouped_data_points, aes(x= input_size, y = time.sec.))
# Linear regression of the points
cols <- c("Real Data" = "#4f72fc", "Linear Model" = "#ff4d4d")
fit <- lm(time.sec. ~ input_size, data = grouped_data_points)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_points, aes(group = input_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(size = 1, aes(x = input_size, y = (input_size * fit$coefficients[2] + fit$coefficients[1]), col = "Linear Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.4, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Number of Points") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
p <- p + ggtitle("")
# <- p + ggtitle(bquote(atop(.("Chan's algorithm with increasing number of points"), atop(italic(.("Hull size: 1000")), ""))))
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
# INCREASING HULL SIZE
grouped_data_hulls <- results_hulls %>% group_by(hull_size)  %>% summarise_each(funs(mean(.)), -iteration_number)#%>% summarise_each(funs(median(.), mean(.), sd(.), min(.), max(.)), -iteration_number, -input_size)
p <- ggplot(grouped_data_hulls, aes(x= hull_size, y = time.sec.))
# Linear regression of the hull size
cols <- c("Real Data" = "#4f72fc", "Logarithmic Model" = "#ff4d4d")
fit <- lm(time.sec. ~ log(hull_size), data = grouped_data_hulls)
pred = seq(1000, 20000, by = 1000)
y_pred = predict(fit, newdata = data.frame(hull_size = pred))
pred_table = data.frame(x = pred, y = y_pred)
p <- p + stat_boxplot(geom ='errorbar', width = 0, data = results_hulls, aes(group = hull_size, y = time.sec., col = "Real Data"), coef = 1)
p <- p + geom_line(data = pred_table, size = 1, aes(x = x, y = y, col = "Logarithmic Model"), lineend = "round", linetype = "twodash")
p <- p + geom_line(size = 1.4, alpha = 0.6, aes(col = "Real Data"), linetype = "solid") + geom_point(size = 2, color ="#021f91")
p <- p + theme_minimal() + xlab("Size of the Hull") + ylab("Execution time [sec]")
p <- p + theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p <- p + scale_y_continuous(labels = comma)
#p <- p + ggtitle(bquote(atop(.("Chan's algorithm with hulls of increasing size"), atop(italic(.("Total number of points: 40000")), ""))))
p <- p + ggtitle
p <- p + scale_colour_manual(name="",values=cols) + theme(legend.position="top")
p
